{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ðŸ› ï¸ **Interactive OpenAI Function Calling Tutorial** \n",
    "\n",
    "earn by doing! This interactive tutorial lets walks through creating a function and then you can chat with the Assistant to use it.\n",
    "\n",
    "Get an intuitive understanding of Function Calling in under 5 mins!!\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ¤” **What is Function Calling?**\n",
    "\n",
    "Function calling is a powerful feature that empowers ChatGPT to *act*. By defining specific abilities (or functions), you grant ChatGPT the capability to perform them based on user prompts.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ **What to Expect in this Notebook**\n",
    "\n",
    "In this notebook, we'll look at examples to understand how function calling operates:\n",
    "\n",
    "1. ðŸŽˆ **Simple Example:** Balloon launch function\n",
    "2. ðŸŒ¦ï¸ **Advanced Example:** Fetch weather info function\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ› ï¸ **Get Creative!**\n",
    "This notebook is easy to modify. Feel free to use this as a base to build your own functions and experiment ðŸ§ª\n",
    "\n",
    "### ðŸ› ï¸ **About**\n",
    "ðŸ‘¤ **Creator:** [Josh Bickett](https://twitter.com/josh_bickett)\n",
    "\n",
    "ðŸ“˜ **Colab:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/joshbickett/function-calling-notebook/blob/main/interactive-function-calling-notebook.ipynb)\n",
    "\n",
    "ðŸ”— **Github:** [View on GitHub](https://github.com/joshbickett/function-calling-notebook)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import openai\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = 'YOUR_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def launch_water_balloon(balloon_size):\n",
    "    hit_locations = ['the ground', 'a tree', 'the moon']\n",
    "    random_location = random.choice(hit_locations)\n",
    "    launch_results = f'Launching the {balloon_size} water balloon, it hit {random_location}!'\n",
    "    return launch_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"launch_water_balloon\",\n",
    "        \"description\": \"This function launches a hypothetical water balloon\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"balloon_size\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"Large\", \"Medium\", \"Small\"],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"balloon_size\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "available_functions = {\n",
    "    \"launch_water_balloon\": launch_water_balloon,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSPECT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def converse(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "    \n",
    "    \n",
    "    messages.append(response_message) \n",
    "    if response_message.get(\"function_call\"):\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        if INSPECT:\n",
    "          print('[inspector] Oh, we got a function call! ðŸ”¨')\n",
    "          print('[inspector] ===> function_name', function_name)\n",
    "          print('[inspector] ===> function_args', function_args)\n",
    "        function_response = function_to_call(\n",
    "            balloon_size=function_args.get(\"balloon_size\"),\n",
    "        )\n",
    "        if INSPECT:\n",
    "          print('[inspector] ===> function_response', function_response)\n",
    "\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print('Assistant: ', function_response)\n",
    "        \n",
    "    else: \n",
    "        content = response_message.get(\"content\")\n",
    "        print('Assistant: ', content)\n",
    "\n",
    "    \n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "message_count = 0 \n",
    "while message_count < 10: \n",
    "    user_input = input(\"User: \")\n",
    "    user_message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages.append(user_message)\n",
    "    converse(messages)\n",
    "    message_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "cities = [\n",
    "    {\"name\": \"San Francisco\", \"latitude\": 37.7749, \"longitude\": -122.4194},\n",
    "    {\"name\": \"New York City\", \"latitude\": 40.7128, \"longitude\": -74.0060},\n",
    "    {\"name\": \"Los Angeles\", \"latitude\": 34.0522, \"longitude\": -118.2437},\n",
    "    {\"name\": \"Chicago\", \"latitude\": 41.8781, \"longitude\": -87.6298},\n",
    "    {\"name\": \"Miami\", \"latitude\": 25.7617, \"longitude\": -80.1918}\n",
    "]\n",
    "\n",
    "def get_weather_data(city_name):\n",
    "    # Find the city object by name\n",
    "    city = next((c for c in cities if c[\"name\"] == city_name), None)\n",
    "\n",
    "    # If city is found, get the weather data using its coordinates\n",
    "    if city:\n",
    "        # Construct the URL based on the city's latitude and longitude\n",
    "        url = f\"https://api.weather.gov/points/{city['latitude']},{city['longitude']}\"\n",
    "\n",
    "        # Make a request to the URL\n",
    "        response = requests.get(url)\n",
    "        \n",
    "\n",
    "        # Ensure the response status is 200 (OK)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            # Extracting the forecast URL from the response\n",
    "            forecast_url = data[\"properties\"][\"forecast\"]\n",
    "\n",
    "            # Fetch the actual forecast data using the extracted URL\n",
    "            forecast_response = requests.get(forecast_url)\n",
    "\n",
    "            if forecast_response.status_code == 200:\n",
    "                forecast_data = forecast_response.json()\n",
    "                tonight_forecast = forecast_data['properties']['periods'][0]\n",
    "\n",
    "                # Display the forecast\n",
    "                return tonight_forecast['detailedForecast']\n",
    "            else:\n",
    "                print(f\"Error fetching forecast data. HTTP Status Code: {forecast_response.status_code}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Error fetching grid point data. HTTP Status Code: {response.status_code}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"City '{city_name}' not found in the list.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [{\n",
    "    \"name\": \"get_weather_data\",\n",
    "    \"description\": \"This function can get weather information for some of the US's largest cities\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"San Francisco\", \"New York City\", \"Los Angeles\", \"Chicago\", \"Miami\"],\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"city_name\"],\n",
    "    },\n",
    "}]\n",
    "available_functions = {\n",
    "    \"get_weather_data\": get_weather_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def converse(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "    \n",
    "    \n",
    "    messages.append(response_message) \n",
    "    if response_message.get(\"function_call\"):\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        if INSPECT:\n",
    "          print('[inspector] Oh, we got a function call! ðŸ”¨')\n",
    "          print('[inspector] ===> function_name', function_name)\n",
    "          print('[inspector] ===> function_args', function_args)\n",
    "        function_response = function_to_call(\n",
    "            city_name=function_args.get(\"city_name\"),\n",
    "        )\n",
    "        if INSPECT:\n",
    "          print('[inspector] ===> function_response', function_response)\n",
    "\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print('Assistant: ', function_response)\n",
    "        \n",
    "    else: \n",
    "        content = response_message.get(\"content\")\n",
    "        print('Assistant: ', content)\n",
    "\n",
    "    \n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "message_count = 0 \n",
    "while message_count < 10: \n",
    "    user_input = input(\"User: \")\n",
    "    user_message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages.append(user_message)\n",
    "    converse(messages)\n",
    "    message_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
